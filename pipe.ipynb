{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import scipy.io as spio\n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import ShuffleSplit, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Create features data frame for a specific subject\n",
    "\n",
    "from tkinter import Tk, filedialog\n",
    "import glob\n",
    "root = Tk() # pointing root to Tk() to use it as Tk() in program.\n",
    "root.withdraw() # Hides small tkinter window.\n",
    "root.attributes('-topmost', True) # Opened windows will be active. above all windows despite of selection.\n",
    "path = filedialog.askdirectory() # Returns opened path as str\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "# Choose a folder\n",
    "dir =  glob.glob(os.path.join(path, \"*\", \"\"), recursive = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def getData(dir, before_q=2):\n",
    "\n",
    "    for i in range(dir.__len__()):\n",
    "\n",
    "        movs = glob.glob(os.path.join(dir[i] + \"/*.avi\"))\n",
    "        dfh5_file = glob.glob(os.path.join(dir[i] + \"/*30000.h5\"))\n",
    "        vidcap = cv2.VideoCapture(movs[0])\n",
    "        success, image = vidcap.read()\n",
    "        print(\"Able to read Mouse \" + str(i) + \" movie?: \" + str(success))\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = frame_count / fps\n",
    "\n",
    "        # load facial points\n",
    "        dfh5 = pd.read_hdf(dfh5_file[0])\n",
    "\n",
    "        # Clac Center of mass\n",
    "        row = dfh5.iloc[[2]]\n",
    "        row = np.squeeze(row.to_numpy())\n",
    "        nose = row[:2]\n",
    "        ear = row[12:14]\n",
    "        center_of_mass = np.mean([nose, ear], axis=0)\n",
    "\n",
    "        # Subtract CoM\n",
    "        dfh5.iloc[:, [0, 3, 6, 9, 12]] -= center_of_mass[0]\n",
    "        dfh5.iloc[:, [1, 4, 7, 10, 13]] -= center_of_mass[1]\n",
    "\n",
    "        # convert to np\n",
    "        pos_df = dfh5.iloc[1:, [0, 1, 3, 4, 6, 7, 9, 10, 12, 13]]\n",
    "\n",
    "        pos_df.to_csv(os.path.join(dir[i] + \"out.csv\"))\n",
    "        pos = pos_df.to_numpy()\n",
    "\n",
    "        # pupil\n",
    "        dfh5_pupil_file = glob.glob(os.path.join(dir[i] + \"/*40000.h5\"))\n",
    "        if dfh5_pupil_file:\n",
    "            dfh5_pupil = pd.read_hdf(dfh5_pupil_file)\n",
    "\n",
    "            dist = lambda x, y: np.linalg.norm(x - y)\n",
    "\n",
    "            pupil = dfh5_pupil.iloc[1:, [0, 1, 3, 4, 6, 7, 9, 10, 12, 13]]\n",
    "            pupil = pupil.to_numpy()\n",
    "\n",
    "            # i_up = pupil[:, 0:2] |  i_down = pupil[:, 2:4]  |  i_right = pupil[:, 4:6] |  i_left = pupil[:, 6:8]\n",
    "            dist_hor = list(map(dist, pupil[:, 0:2], pupil[:, 4:6]))\n",
    "            dist_ver = list(map(dist, pupil[:, 4:6], pupil[:, 6:8]))\n",
    "            pos_n_pupil = np.concatenate((pos, dist_hor, dist_ver), axis=1)\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"Mouse \" + str(i) + \" have no pupil file\")\n",
    "            pos_n_pupil = pos\n",
    "\n",
    "        # run matlab code if necessary\n",
    "\n",
    "        # get session data\n",
    "        data = spio.loadmat(os.path.join(dir[i] + 'data.mat'))\n",
    "\n",
    "        correction = pos_n_pupil.shape[0] / ((data['time'].shape[1] / data['Fs']) * fps)\n",
    "\n",
    "        tSOS_new = data['tSOS'] * correction\n",
    "        Lick_times_new = np.ravel(data['Lick_times'] * correction + (\n",
    "                tSOS_new[0] - np.minimum(data['Go_times'][0, 0], data['NoGo_times'][0, 0])))\n",
    "\n",
    "        stimuli = np.sort(np.append(data['Go_times'], data['NoGo_times'])) * correction\n",
    "        stimuli_type = np.in1d(stimuli, data['Go_times'] * correction)\n",
    "\n",
    "        # movie interpolation\n",
    "        r = pd.RangeIndex(0, int((data['time'].shape[1] / data['Fs']) * fps), 1)\n",
    "        t = pos_df\n",
    "        t = t.sort_index()\n",
    "        new_idx = np.linspace(t.index[0], len(r), len(r))\n",
    "        t = (t.reindex(new_idx, method='ffill', limit=1).iloc[1:].interpolate())\n",
    "\n",
    "        pos_n_pupil = t.to_numpy()\n",
    "\n",
    "        # segment to trails\n",
    "        for idx, seg in enumerate(data['tSOS'] * fps):\n",
    "            segment = pos_n_pupil[int(seg - before_q * fps):int(seg), :].reshape([int(before_q * fps) * pos_n_pupil.shape[1]])\n",
    "            lick_seg = np.any(np.ravel(np.where((Lick_times_new > seg / fps) & (Lick_times_new < seg / fps + before_q))))\n",
    "            if idx == 0:\n",
    "                x = segment\n",
    "                y = lick_seg\n",
    "            else:\n",
    "                x = np.row_stack((x, segment))\n",
    "                y = np.row_stack((y, lick_seg))\n",
    "\n",
    "        # concat this mouse data to the others\n",
    "\n",
    "\n",
    "\n",
    "            # create empty arrays\n",
    "        if i == 0:\n",
    "            X = x\n",
    "            y_tot = y\n",
    "            stimuli_tot = stimuli_type\n",
    "        X = np.concatenate((X, x), axis=0)\n",
    "        print(x.shape)\n",
    "\n",
    "        y_tot = np.concatenate((y_tot, y), axis=0)\n",
    "        stimuli_tot = np.concatenate((stimuli_tot, stimuli_type), axis=0)\n",
    "        print(stimuli_type.shape)\n",
    "\n",
    "\n",
    "    return X, np.ravel(y_tot), np.ravel(stimuli_tot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Able to read Mouse 0 movie?: True\n",
      "Mouse 0 have no pupil file\n",
      "(51, 150)\n",
      "(51,)\n",
      "Able to read Mouse 1 movie?: True\n",
      "Mouse 1 have no pupil file\n",
      "(58, 150)\n",
      "(56,)\n",
      "Able to read Mouse 2 movie?: True\n",
      "Mouse 2 have no pupil file\n",
      "(51, 150)\n",
      "(51,)\n",
      "Able to read Mouse 3 movie?: True\n",
      "Mouse 3 have no pupil file\n",
      "(66, 150)\n",
      "(66,)\n",
      "Able to read Mouse 4 movie?: True\n",
      "Mouse 4 have no pupil file\n",
      "(69, 150)\n",
      "(69,)\n",
      "Able to read Mouse 5 movie?: True\n",
      "Mouse 5 have no pupil file\n",
      "(67, 150)\n",
      "(61,)\n",
      "Able to read Mouse 6 movie?: True\n",
      "Mouse 6 have no pupil file\n",
      "(56, 150)\n",
      "(56,)\n",
      "Able to read Mouse 7 movie?: True\n",
      "Mouse 7 have no pupil file\n",
      "(62, 150)\n",
      "(62,)\n"
     ]
    }
   ],
   "source": [
    "X, y, stimuli_type = getData(dir, before_q=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# smoothing\n",
    "# from scipy.signal import savgol_filter, filtfilt, ellip\n",
    "# b, a = ellip(4, 0.01, 120, 0.125)  # Filter to be applied.\n",
    "#\n",
    "# X_hat = np.zeros_like(X)\n",
    "# for i in range(X.shape[0]):\n",
    "#     X_hat[:,i] = filtfilt(b, a,X[:,i], method=\"gust\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 531 and the array at index 1 has size 523",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [126]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# add the stimuli sounds\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_\u001B[49m\u001B[43m[\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstimuli_type\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\numpy\\lib\\index_tricks.py:412\u001B[0m, in \u001B[0;36mAxisConcatenator.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m scalars:\n\u001B[0;32m    410\u001B[0m         objs[k] \u001B[38;5;241m=\u001B[39m objs[k]\u001B[38;5;241m.\u001B[39mastype(final_dtype)\n\u001B[1;32m--> 412\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m matrix:\n\u001B[0;32m    415\u001B[0m     oldndim \u001B[38;5;241m=\u001B[39m res\u001B[38;5;241m.\u001B[39mndim\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 531 and the array at index 1 has size 523"
     ]
    }
   ],
   "source": [
    "\n",
    "# add the stimuli sounds\n",
    "X = np.c_[X, stimuli_type]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8347196261682243 || STD: 0.03301033936545144\n",
      "Train accuracy: 0.855 || STD: 0.007284491248175741\n"
     ]
    }
   ],
   "source": [
    "K = 200\n",
    "acc = np.zeros([K,2])\n",
    "\n",
    "\n",
    "for k in range(K):\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Feature Scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # pca = PCA(n_components=10)\n",
    "    # pca.fit_transform(X_train, y_train)\n",
    "    # pca.fit(X_test)\n",
    "\n",
    "\n",
    "    # Training and Making Predictions\n",
    "    # classifier = GaussianNB()\n",
    "    classifier = svm.SVC()\n",
    "    # classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc[k,0] = accuracy_score(y_test, y_pred)\n",
    "    train_pred = classifier.predict(X_train)\n",
    "    acc[k,1] = accuracy_score(y_train, train_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluating the Performance\n",
    "print('Test accuracy: ' + str(np.mean(acc[:, 0])) + ' || STD: ' + str(np.std(acc[:, 0])))\n",
    "print('Train accuracy: ' + str(np.mean(acc[:, 1])) + ' || STD: ' + str(np.std(acc[:, 1])))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}